{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does More Data Always Improve Predictions?\n",
    "\n",
    "In machine learning, it is commonly believed that more data leads to better predictions. After all, companies with access to vast amounts of data can build more sophisticated models that provide highly accurate predictions, such as predicting user behavior. However, in certain cases, adding more data can lead to less accurate predictions.\n",
    "\n",
    "This phenomenon was observed in our previous example: when we had only five cabins in the dataset, the model provided perfect predictions. But when we added a sixth cabin, the accuracy decreased. This leads to an important distinction in machine learning between **training data** and **test data**.\n",
    "\n",
    "In the previous example, we evaluated the prediction accuracy using the same data that we trained the model on. This scenario, while ideal for demonstration purposes, does not reflect a real-world use case. In practice, we are more concerned with how well the model performs on new data that it hasn't seen before—this is where **test data** comes into play."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Importance of Training and Testing in Machine Learning\n",
    "\n",
    "When building a predictive model, it is crucial to evaluate its performance on unseen data. This is why machine learning workflows often involve splitting the dataset into two parts:\n",
    "\n",
    "- **Training data**: This is used to fit the model and learn the relationships between the input features and the output.\n",
    "\n",
    "- **Test data**: This is used to assess the model's ability to generalize to new, unseen instances. The test data contains the actual outputs (prices in this case), but the model should not use this information when making predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Example: Predicting Cabin Prices Using Separate Training and Test Sets\n",
    "\n",
    "In this exercise, we will simulate a real-world scenario where the goal is to predict the prices of cabins based on their features. We will use two separate datasets:\n",
    "\n",
    "- **Training data**: A set of six cabins with known features and prices.\n",
    "- **Test data**: A separate set of two cabins, for which the actual prices are provided but will not be used in the prediction process.\n",
    "\n",
    "The model will first be trained on the training dataset to estimate the regression coefficients, and then use these coefficients to predict the prices of the cabins in the test dataset.\n",
    "\n",
    "### Training Data\n",
    "\n",
    "| Cabin   | Size (sqm) | Sauna Size (sqm) | Distance to Water (m) | Number of Indoor Bathrooms | Proximity to Neighbors (m) | Price (€) |\n",
    "|---------|------------|------------------|-----------------------|----------------------------|----------------------------|-----------|\n",
    "| Cabin 1 | 25         | 2                | 50                    | 1                          | 500                        | 127,900   |\n",
    "| Cabin 2 | 39         | 3                | 10                    | 1                          | 1000                       | 222,100   |\n",
    "| Cabin 3 | 13         | 2                | 13                    | 1                          | 1000                       | 143,750   |\n",
    "| Cabin 4 | 82         | 5                | 20                    | 2                          | 120                        | 268,000   |\n",
    "| Cabin 5 | 130        | 6                | 10                    | 2                          | 600                        | 460,700   |\n",
    "| Cabin 6 | 115        | 6                | 10                    | 1                          | 550                        | 407,000   |\n",
    "\n",
    "### Test Data\n",
    "\n",
    "| Cabin   | Size (sqm) | Sauna Size (sqm) | Distance to Water (m) | Number of Indoor Bathrooms | Proximity to Neighbors (m) | Price (€) |\n",
    "|---------|------------|------------------|-----------------------|----------------------------|----------------------------|-----------|\n",
    "| Cabin 1 | 36         | 3                | 15                    | 1                          | 850                        | 196,000   |\n",
    "| Cabin 2 | 75         | 5                | 18                    | 2                          | 540                        | 290,000   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the Model\n",
    "\n",
    "We'll implement the solution by first reading the training and test data, then using the least squares method to estimate the regression coefficients from the training data. Finally, we'll use these coefficients to predict the prices of the cabins in the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2989.6  800.6  -44.8 3890.8   99.8]\n",
      "[198102.4 289108.3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from io import StringIO\n",
    "\n",
    "# Define the training data\n",
    "train_string = '''\n",
    "25 2 50 1 500 127900\n",
    "39 3 10 1 1000 222100\n",
    "13 2 13 1 1000 143750\n",
    "82 5 20 2 120 268000\n",
    "130 6 10 2 600 460700\n",
    "115 6 10 1 550 407000\n",
    "'''\n",
    "\n",
    "# Define the test data\n",
    "test_string = '''\n",
    "36 3 15 1 850 196000\n",
    "75 5 18 2 540 290000\n",
    "'''\n",
    "\n",
    "def main():\n",
    "    np.set_printoptions(precision=1)    # Set output precision for easier reading\n",
    "    \n",
    "    # Load the training data\n",
    "    train_data = np.genfromtxt(StringIO(train_string), skip_header=0)\n",
    "    \n",
    "    # Read in the training data and separate it to x_train and y_train\n",
    "    x_train = train_data[:, :-1] \n",
    "    y_train = train_data[:, -1]\n",
    "\n",
    "    # Using the least squares method to the data and get the coefficients\n",
    "    c = np.linalg.lstsq(x_train, y_train, rcond=None)[0]\n",
    "\n",
    "    # Read in the test data and separate x_test from it\n",
    "    test_data = np.genfromtxt(StringIO(test_string), skip_header=0)\n",
    "    x_test = test_data[:, :-1]\n",
    "\n",
    "    # Print out the linear regression coefficients\n",
    "    print(c)\n",
    "\n",
    "    # Print out the predicted prics for the two new cabins in the test data set\n",
    "    print(x_test @ c)\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the Output\n",
    "\n",
    "After running the program, we get two sets of outputs:\n",
    "\n",
    "- The **estimated coefficients** for the linear regression model based on the training data.\n",
    "\n",
    "- The **predicted prices** for the cabins in the test set.\n",
    "- \n",
    "The predicted prices might differ from the actual prices in the test data because the model has not seen these data points before. This discrepancy highlights the importance of generalization—how well a model trained on one set of data performs on new, unseen data.\n",
    "\n",
    "## Understanding Model Accuracy\n",
    "\n",
    "In our example, even though the training data perfectly fit the model (since there are enough coefficients to match each data point exactly), the model’s performance on the test data is a better indicator of its real-world applicability. This aligns with a common practice in machine learning: evaluating model accuracy on a separate test set helps avoid overfitting, where the model is too finely tuned to the training data and performs poorly on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This exercise demonstrated how separating data into training and test sets is crucial for assessing a model's ability to generalize to new data. By training the model on one dataset and testing it on another, we simulate real-world applications where the model needs to make predictions on unseen data.\n",
    "\n",
    "The linear regression method, combined with the least squares approach, provides a solid foundation for predictive modeling. As datasets grow larger and more complex, techniques like these will continue to be essential in building robust, interpretable models.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
